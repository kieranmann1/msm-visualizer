{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#old_file = pd.read_csv('old_structure/resultFile.csv', header = None)\n",
    "#old_file\n",
    "\n",
    "import csv\n",
    "with open ('old_structure/resultFile1.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))\n",
    "# Data is a list object\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "validation = 0\n",
    "rowcounter = 0\n",
    "\n",
    "yearcounter = int(data[0][0][5:])\n",
    "blockcounter = 0\n",
    "linecounter = 0\n",
    "newdatabase = []\n",
    "while i < len(data):\n",
    "    if(data[i][0] == 'Housing costs by income group'):\n",
    "        validation = 1\n",
    "        linecounter = 0\n",
    "        \n",
    "        i=i+1 \n",
    "    else:\n",
    "        if(data[i][0] == 'jobByRegion'):\n",
    "            validation = 0\n",
    "            yearcounter = yearcounter + 1\n",
    "        if(validation == 1):\n",
    "            if(linecounter ==0):\n",
    "                linecounter = linecounter + 1\n",
    "                header = data[i]\n",
    "                header.insert(0,'year')\n",
    "            else:\n",
    "                data[i].insert(0, yearcounter)\n",
    "                newdatabase.append(data[i])\n",
    "        i=i+1\n",
    "\n",
    "dataframe = pd.DataFrame(newdatabase, columns = header)\n",
    "dataframe\n",
    "    \n",
    "#dataframe.to_csv('hhRentAndIncome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def siloOutputParser(startpoint, endpoint, databasename, ignoreFirstLine, ignoreHeader):\n",
    "    \n",
    "    ## Starting values\n",
    "    i = 0\n",
    "    parserData = copy.deepcopy(data)\n",
    "    yearcounter = int(parserData[0][0][5:])\n",
    "    linecounter = 0\n",
    "    blockcounter = 0\n",
    "    newdatabase = []\n",
    "    validation = 0\n",
    "    ## Parser loop\n",
    "    \n",
    "    while i < len(parserData):\n",
    "        if(ignoreHeader == False):\n",
    "            if(parserData[i][0] == startpoint):\n",
    "                validation = 1\n",
    "                linecounter = 0\n",
    "                if(ignoreFirstLine == False):\n",
    "                    header = parserData[i]\n",
    "                    header.insert(0,'year')\n",
    "                i=i+1\n",
    "            else:\n",
    "                if(parserData[i][0] == endpoint):\n",
    "                    validation = 0\n",
    "                    yearcounter = yearcounter + 1\n",
    "                if(validation == 1):\n",
    "                    if(linecounter == 0):\n",
    "                        linecounter = linecounter + 1\n",
    "                        if(ignoreFirstLine == True):\n",
    "                            header = parserData[i]\n",
    "                            header.insert(0,'year')\n",
    "                        else:\n",
    "                            parserData[i].insert(0, yearcounter)\n",
    "                            newdatabase.append(parserData[i])                           \n",
    "                    else:\n",
    "                        parserData[i].insert(0, yearcounter)\n",
    "                        newdatabase.append(parserData[i])\n",
    "                i=i+1\n",
    "            \n",
    "        else:\n",
    "            if(parserData[i][0] == startpoint):\n",
    "                validation = 1\n",
    "                linecounter = 0\n",
    "            if(parserData[i][0] == endpoint):\n",
    "                validation = 0\n",
    "                yearcounter = yearcounter +1\n",
    "            if(validation == 1):\n",
    "                if(ignoreFirstLine == True):\n",
    "                    if(linecounter >0):\n",
    "                        parserData[i].insert(0, yearcounter)\n",
    "                        newdatabase.append(parserData[i])\n",
    "                else:\n",
    "                    parserData[i].insert(0, yearcounter)\n",
    "                    newdatabase.append(parserData[i])\n",
    "                linecounter = linecounter + 1\n",
    "            i=i+1\n",
    "    #return dataframe\n",
    "    if(ignoreHeader == False):\n",
    "        dataframe = pd.DataFrame(newdatabase, columns = header)\n",
    "    else:\n",
    "        dataframe = pd.DataFrame(newdatabase)\n",
    "    dataframe.to_csv(databasename, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siloOutputParser('Housing costs by income group','jobByRegion','hhRentAndIncome.csv',True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siloOutputParser('ppByRace','hhByType','persByRace.csv',False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siloOutputParser('InmigrantsPP','Count of simulated events','persMigrants.csv',False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siloOutputParser('aveCommuteDistByRegion','carOwnershipLevel','regionAvCommutingTime.csv',False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siloOutputParser('Available land for construction by region','Housing costs by income group','regionAvailableLand.csv',True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siloOutputParser('QualityLevel','CountOfDD','dwellingQualityLevel.csv',False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siloOutputParser('jobByRegion','InmigrantsPP','jobsBySectorAndRegion.csv',False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
